{"id": "case_product", "question": "What risks and milestones should the planner summarize?", "baseline": {"answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "usage": {"prompt_tokens": 312, "completion_tokens": 65, "total_tokens": 377}, "latency_seconds": 0.054018167007598095, "prompt_chars": 1249, "policy_name": "quantum_brain_v0_baseline"}, "brain": {"answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "plan": {"difficulty": "medium", "max_reasoning_passes": 2, "needs_full_context": false, "strategy": "cascade_small_then_big", "target_expert_tokens": 256, "target_latency_ms": 400, "speculation_mode": "off", "notes_for_reasoner": "Answer succinctly and cite facts.", "usage": {"prompt_tokens": 183, "completion_tokens": 65, "total_tokens": 248}, "latency_seconds": 0.054982875008136034}, "policy_name": "quantum_brain_v0", "strategy_used": "cascade_small_then_big", "speculation_mode": "off", "debug": {"canvas": {"raw_chunks": ["The product strategy review describes a neuro-symbolic assistant designed for daily planning\nand health monitoring. The memo states that customers struggle with chaotic schedules, so the\nteam proposes a multi-stage architecture that first compresses calendar streams and wearable\ndata into a structured canvas. This canvas contains timelines of predicted commitments,\nentities such as teammates, medications, and devices, and direct quotes from recent\ncommunications. The expert reasoning module then performs scenario planning, highlighting\nrisks like missed handoffs, medication conflicts, or duplicate meetings. Key milestones:\n- Q3 pilot with ten enterprise teams that already adopted the context compression plugin.\n- Q4 expansion that integrates with hospital record systems and adds clinician review loops.\nThe risks listed include data quality gaps, regulatory questions for medical guidance, and\nlatency when downloading raw transcripts. The memo emphasizes that a lightweight controller\nshould adapt reasoning depth to difficulty so latency and token usage remain low."], "summaries": [], "facts": [], "entities": [], "quotes": [], "notes_for_reasoner": "Answer succinctly and cite facts."}, "intermediate_steps": ["{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}"], "chunk_summaries": [{"chunk_index": 1, "usage": {"prompt_tokens": 387, "completion_tokens": 65, "total_tokens": 452}, "summary": {"difficulty": "medium", "max_reasoning_passes": 2, "needs_full_context": false, "strategy": "cascade_small_then_big", "target_expert_tokens": 256, "target_latency_ms": 400, "speculation_mode": "off", "notes_for_reasoner": "Answer succinctly and cite facts.", "summary": "", "facts": [], "entities": [], "quotes": []}}], "stages": [{"stage_name": "cascade_small", "model": "gpt-4o-mini", "final_answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "intermediate_steps": ["{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}"], "usage": [{"prompt_tokens": 176, "completion_tokens": 65, "total_tokens": 241}, {"prompt_tokens": 246, "completion_tokens": 65, "total_tokens": 311}], "step_latencies": [0.054429874988272786, 0.05447025000466965], "confidence": 0.518}, {"stage_name": "cascade_expert", "model": "gpt-4o", "final_answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "intermediate_steps": ["{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}"], "usage": [{"prompt_tokens": 176, "completion_tokens": 65, "total_tokens": 241}, {"prompt_tokens": 246, "completion_tokens": 65, "total_tokens": 311}], "step_latencies": [0.05509612501191441, 0.052031416998943314], "confidence": 0.518}], "encoder_from_cache": false}, "usage": {"encoder_tokens": {"prompt_tokens": 387, "completion_tokens": 65, "total_tokens": 452}, "controller_tokens": {"prompt_tokens": 183, "completion_tokens": 65, "total_tokens": 248}, "reasoner_tokens": {"prompt_tokens": 844, "completion_tokens": 260, "total_tokens": 1104}}, "latency_seconds": 0.32249958300963044, "reasoner_latency_seconds": 0.21602766700380016}, "expected_notes": null, "doc_id": "case_product", "policy_name": "quantum_brain_v0"}
{"id": "case_risk", "question": "List the major risks and mitigation steps for the LATAM fintech plans.", "baseline": {"answer": "EXPERT answer 1: You are an expert analyst. Answer the QUESTION using the CONTEXT below.\n        QUESTION: List the major risks and mitig", "usage": {"prompt_tokens": 230, "completion_tokens": 35, "total_tokens": 265}, "latency_seconds": 0.055086916996515356, "prompt_chars": 921, "policy_name": "quantum_brain_v0_baseline"}, "brain": {"answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "plan": {"difficulty": "medium", "max_reasoning_passes": 2, "needs_full_context": false, "strategy": "cascade_small_then_big", "target_expert_tokens": 256, "target_latency_ms": 400, "speculation_mode": "off", "notes_for_reasoner": "Answer succinctly and cite facts.", "usage": {"prompt_tokens": 202, "completion_tokens": 65, "total_tokens": 267}, "latency_seconds": 0.055094374998589046}, "policy_name": "quantum_brain_v0", "strategy_used": "cascade_small_then_big", "speculation_mode": "off", "debug": {"canvas": {"raw_chunks": ["A compliance briefing outlines three categories of risk for a fintech launch in Latin America.\nFirst, macroeconomic volatility could reduce consumer lending appetite; the analysts cite\nArgentina's sudden policy shifts and Brazil's fluctuating benchmark rates. Second, data\nresidency laws require that sensitive financial telemetry remains inside national borders, so\nengineering must prepare hybrid deployments. Third, competition from super-app providers may\nundercut pricing. The document quotes regional partners describing the need for multilingual\nsupport teams and automated monitoring of rule changes. Proposed mitigations: phased rollouts\nstarting with Brazil and Chile, automated legal alerts, and frequent tabletop exercises."], "summaries": ["Chunk summary"], "facts": ["Fact A"], "entities": [{"name": "Example", "type": "concept", "description": "placeholder"}], "quotes": ["\"Quoted detail\""], "notes_for_reasoner": null}, "intermediate_steps": ["{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}"], "chunk_summaries": [{"chunk_index": 1, "usage": {"prompt_tokens": 305, "completion_tokens": 49, "total_tokens": 354}, "summary": {"summary": "Chunk summary", "facts": ["Fact A"], "entities": [{"name": "Example", "type": "concept", "description": "placeholder"}], "quotes": ["\"Quoted detail\""], "notes_for_reasoner": ""}}], "stages": [{"stage_name": "cascade_small", "model": "gpt-4o-mini", "final_answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "intermediate_steps": ["{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}"], "usage": [{"prompt_tokens": 188, "completion_tokens": 65, "total_tokens": 253}, {"prompt_tokens": 258, "completion_tokens": 65, "total_tokens": 323}], "step_latencies": [0.05513175000669435, 0.05511474999366328], "confidence": 0.518}, {"stage_name": "cascade_expert", "model": "gpt-4o", "final_answer": "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "intermediate_steps": ["{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}", "{\"difficulty\": \"medium\", \"max_reasoning_passes\": 2, \"needs_full_context\": false, \"strategy\": \"cascade_small_then_big\", \"target_expert_tokens\": 256, \"target_latency_ms\": 400, \"speculation_mode\": \"off\", \"notes_for_reasoner\": \"Answer succinctly and cite facts.\"}"], "usage": [{"prompt_tokens": 188, "completion_tokens": 65, "total_tokens": 253}, {"prompt_tokens": 258, "completion_tokens": 65, "total_tokens": 323}], "step_latencies": [0.05507995799416676, 0.05345741599739995], "confidence": 0.518}], "encoder_from_cache": false}, "usage": {"encoder_tokens": {"prompt_tokens": 305, "completion_tokens": 49, "total_tokens": 354}, "controller_tokens": {"prompt_tokens": 202, "completion_tokens": 65, "total_tokens": 267}, "reasoner_tokens": {"prompt_tokens": 892, "completion_tokens": 260, "total_tokens": 1152}}, "latency_seconds": 0.32937620898883324, "reasoner_latency_seconds": 0.21878387399192434}, "expected_notes": null, "doc_id": "case_risk", "policy_name": "quantum_brain_v0"}